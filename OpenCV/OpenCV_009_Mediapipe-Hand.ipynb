{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "181b1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 동영상과 mediapipe-hand 를 연결하기\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 손을 찾는 기능 불러오기\n",
    "mp_hands = mp.solutions.hands\n",
    "# 특징점 그리기 설정\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 손 특징점 찾기 관련 설정\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 2,\n",
    "    min_detection_confidence = 0.5, # 손 검출 확률(자체판단) 50%이상인 것들만 출력하기\n",
    "    min_tracking_confidence = 0.5 # 특징점 검출 확률(자체 판단) 50%이상인 것들만 출력하기\n",
    ")\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    if not ret:\n",
    "        break\n",
    "    # 이미지에서 원하는 대상(손) 찾기   \n",
    "    result = hands.process(img)\n",
    "    # 손을 검출했다면 표현하기(21개의 특징점을 찾음)\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        # 21개 특징점을 하나씩 그려주기\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "        \n",
    "    \n",
    "    cv2.imshow('video',img)\n",
    "    if cv2.waitKey(33) == 49:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c73b72-ea49-489b-8a96-eccbc8929c16",
   "metadata": {},
   "source": [
    "1. 손에서 특징점 21개 찾기 완료\r\n",
    "2. 특징점들을 연결해서 뼈 만들기\r\n",
    "3. 뼈와 뼈 사이의 각도 구하기\r\n",
    "   - 동작에 따라 각도의 변화가 많은 15개의 각도 사용\r\n",
    "4. KNN에 예측시켜서 어떤 동작인지 구분하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90fe688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 동영상과 mediapipe-hand 를 연결하기\n",
    "## 한 손의 동작 인식하기\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "gesture = {\n",
    "    0:'fist', 1:'one', 2:'two', 3:'three', 4:'four', 5:'five',\n",
    "    6:'six', 7:'rock', 8:'spiderman', 9:'yeah', 10:'ok',\n",
    "}\n",
    "\n",
    "# gesture_train을 머신러닝 모델에 학습\n",
    "import numpy as np\n",
    "file = np.genfromtxt('images/gesture_train.csv', delimiter = \",\")\n",
    "angle = file[:, :-1].astype(np.float32) # 문제데이터\n",
    "label = file[:, -1].astype(np.float32) # 정답데이터\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(angle, label)\n",
    "\n",
    "# 손을 찾는 기능 불러오기\n",
    "mp_hands = mp.solutions.hands\n",
    "# 특징점 그리기 설정\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 손 특징점 찾기 관련 설정\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 1,\n",
    "    min_detection_confidence = 0.5, # 손 검출 확률(자체판단) 50%이상인 것들만 출력하기\n",
    "    min_tracking_confidence = 0.5 # 특징점 검출 확률(자체 판단) 50%이상인 것들만 출력하기\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    if not ret:\n",
    "        break\n",
    "    # 이미지에서 원하는 대상(손) 찾기   \n",
    "    result = hands.process(img)\n",
    "    # 손을 검출했다면 표현하기(21개의 특징점을 찾음)\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        # 21개 특징점을 하나씩 그려주기\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            # 21개의 특징점 위치 저장할 용도(x,y,z)\n",
    "            joint = np.zeros((21,3))\n",
    "            # 21개의 특징점 저장\n",
    "            # enumerate : 반복문의 순서를 알려줌, 추가적인 변수 하나가 더 필요\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "            # 특징점을 연결해서 뼈의 값 구하기(좌표값 기반-x,y,z)\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:]\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:]\n",
    "            v = v2 - v1 # [20,3]\n",
    "            # 뼈의 직선 구하기\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            # 뼈의 직선을 통해서 각도 구하기(각도의 변화가 큰 15개만 사)\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:]))\n",
    "            # radian 각도를 degree 각도로 변경하기\n",
    "            angle = np.degrees(angle)\n",
    "\n",
    "            # 학습된 KNN 모델에 동작 예측시키기\n",
    "            # 예측시킬 데이터 전처리하기\n",
    "            data = np.array([angle], dtype=np.float32)\n",
    "            # 예측하기\n",
    "            results = knn.predict(data)\n",
    "            idx = int(results)\n",
    "            \n",
    "            # cv2.putText : 이미지 위에 글씨 쓰기\n",
    "            # 사용할 이미지, 쓸 글씨(영어), 글씨 위치, 폰트, 글씨 크기, 글씨 색깔, 글씨 두께\n",
    "            cv2.putText(img, text=gesture[idx].upper(), org=(int(res.landmark[0].x * img.shape[1]), int(res.landmark[0].y * img.shape[0] + 20)), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    \n",
    "    cv2.imshow('video',img)\n",
    "    if cv2.waitKey(33) == 49:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3759da9a-4e16-4772-8b44-2a406116b4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa394b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 동영상과 mediapipe-hand 를 연결하기\n",
    "## 한 손의 동작 인식하기\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "gesture = {\n",
    "    0:'fist', 1:'one', 2:'two', 3:'three', 4:'four', 5:'five',\n",
    "    6:'six', 7:'rock', 8:'spiderman', 9:'yeah', 10:'ok',\n",
    "}\n",
    "\n",
    "rsp_gesture = {\n",
    "    0:'rock', 9:'scissors', 5:'paper'\n",
    "}\n",
    "\n",
    "# gesture_train을 머신러닝 모델에 학습\n",
    "import numpy as np\n",
    "file = np.genfromtxt('images/gesture_train.csv', delimiter = \",\")\n",
    "angle = file[:, :-1].astype(np.float32) # 문제데이터\n",
    "label = file[:, -1].astype(np.float32) # 정답데이터\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(angle, label)\n",
    "\n",
    "# 손을 찾는 기능 불러오기\n",
    "mp_hands = mp.solutions.hands\n",
    "# 특징점 그리기 설정\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "# 손 특징점 찾기 관련 설정\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands = 2,\n",
    "    min_detection_confidence = 0.5, # 손 검출 확률(자체판단) 50%이상인 것들만 출력하기\n",
    "    min_tracking_confidence = 0.5 # 특징점 검출 확률(자체 판단) 50%이상인 것들만 출력하기\n",
    ")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    if not ret:\n",
    "        break\n",
    "    # 이미지에서 원하는 대상(손) 찾기   \n",
    "    result = hands.process(img)\n",
    "    # 손을 검출했다면 표현하기(21개의 특징점을 찾음)\n",
    "    if result.multi_hand_landmarks is not None:\n",
    "        # 가위바위보 결과 저장할 변\n",
    "        rsp_result = []\n",
    "        # 21개 특징점을 하나씩 그려주기\n",
    "        for res in result.multi_hand_landmarks:\n",
    "            # 21개의 특징점 위치 저장할 용도(x,y,z)\n",
    "            joint = np.zeros((21,3))\n",
    "            # 21개의 특징점 저장\n",
    "            # enumerate : 반복문의 순서를 알려줌, 추가적인 변수 하나가 더 필요\n",
    "            for j, lm in enumerate(res.landmark):\n",
    "                joint[j] = [lm.x, lm.y, lm.z]\n",
    "\n",
    "            # 특징점을 연결해서 뼈의 값 구하기(좌표값 기반-x,y,z)\n",
    "            v1 = joint[[0,1,2,3,0,5,6,7,0,9,10,11,0,13,14,15,0,17,18,19],:]\n",
    "            v2 = joint[[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],:]\n",
    "            v = v2 - v1 # [20,3]\n",
    "            # 뼈의 직선 구하기\n",
    "            v = v / np.linalg.norm(v, axis=1)[:, np.newaxis]\n",
    "            # 뼈의 직선을 통해서 각도 구하기(각도의 변화가 큰 15개만 사)\n",
    "            angle = np.arccos(np.einsum('nt,nt->n',\n",
    "                v[[0,1,2,4,5,6,8,9,10,12,13,14,16,17,18],:], \n",
    "                v[[1,2,3,5,6,7,9,10,11,13,14,15,17,18,19],:]))\n",
    "            # radian 각도를 degree 각도로 변경하기\n",
    "            angle = np.degrees(angle)\n",
    "\n",
    "            # 학습된 KNN 모델에 동작 예측시키기\n",
    "            # 예측시킬 데이터 전처리하기\n",
    "            data = np.array([angle], dtype=np.float32)\n",
    "            # 예측하기\n",
    "            results = knn.predict(data)\n",
    "            idx = int(results)\n",
    "\n",
    "            # cv2.putText : 이미지 위에 글씨 쓰기\n",
    "            # 사용할 이미지, 쓸 글씨(영어), 글씨 위치, 폰트, 글씨 크기, 글씨 색깔, 글씨 두께\n",
    "\n",
    "            # 동작이 주먹, 가위, 보 일때만 실행\n",
    "            if idx in rsp_gesture.keys():\n",
    "                # 주먹, 가위, 보의 동작만 글씨 쓰기\n",
    "                org = (int(res.landmark[0].x * img.shape[1]), int(res.landmark[0].y * img.shape[0]))\n",
    "                cv2.putText(img, text=rsp_gesture[idx].upper(), org=(org[0], org[1] + 20), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 255, 255), thickness=2)\n",
    "\n",
    "                # 주먹, 가위, 보의 동작값 저장하기\n",
    "                rsp_result.append({\n",
    "                    'rsp' : rsp_gesture[idx],\n",
    "                    'org' : org\n",
    "                })\n",
    "                \n",
    "            mp_drawing.draw_landmarks(img, res, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # 누가 이겼나?\n",
    "            # 두 개의 결과값이 저장이 되어야 실행\n",
    "            if len(rsp_result) == 2:\n",
    "                winner = None  # 누가 이겼는지 저장할 변수\n",
    "                text = ''  # 어떤 동작이 이겼는지 저장 or 비김\n",
    "\n",
    "                if rsp_result[0]['rsp'] == 'rock':\n",
    "                    if rsp_result[1]['rsp'] == 'rock': text = 'Tie'\n",
    "                    elif rsp_result[1]['rsp'] == 'paper': text = 'Paper Win'; winner = 1\n",
    "                    elif rsp_result[1]['rsp'] == 'scissors' : text = 'Rock Win'; winner = 0\n",
    "                elif rsp_result[0]['rsp'] == 'paper':\n",
    "                    if rsp_result[1]['rsp'] == 'rock': text = 'Paper Win'; winner = 0\n",
    "                    elif rsp_result[1]['rsp'] == 'paper': text = 'Tie'\n",
    "                    elif rsp_result[1]['rsp'] == 'scissors' : text = 'Scissors Win'; winner = 1\n",
    "                elif rsp_result[0]['rsp'] == 'scissors':\n",
    "                    if rsp_result[1]['rsp'] == 'rock': text = 'Rock Win'; winner = 1\n",
    "                    elif rsp_result[1]['rsp'] == 'paper': text = 'Scissors Win'; winner = 0\n",
    "                    elif rsp_result[1]['rsp'] == 'scissors' : text = 'Tie'\n",
    "\n",
    "                # 이긴 사람 표시하기\n",
    "                if winner is not None:\n",
    "                    cv2.putText(img, text='Winner', org=(rsp_result[winner]['org'][0], rsp_result[winner]['org'][1] + 70), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0, 255, 0), thickness=3)\n",
    "                cv2.putText(img, text=text, org=(int(img.shape[1] / 3), 100), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, color=(0, 0, 255), thickness=3)\n",
    "                \n",
    "    \n",
    "    cv2.imshow('video',img)\n",
    "    if cv2.waitKey(33) == 49:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc59304-a8da-43ed-9ca6-97b002d3f13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381cb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99591f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354dd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c643f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
